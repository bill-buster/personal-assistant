---
description: Testing improvements and Cursor-specific testing patterns
globs: ["**/*.test.ts", "**/run_tests.ts", "src/core/test_utils.ts"]
alwaysApply: false
---

# Testing Improvements & Cursor Patterns

## Test Utilities

Use test utilities from `src/core/test_utils.ts`:

```typescript
import { 
    createMockContext, 
    runCli, 
    assertSuccess, 
    assertError,
    createTestDir,
    cleanupTestDir 
} from '../core/test_utils';

// Create mock context
const context = createMockContext({
    memoryPath: '/custom/path',
});

// Run CLI commands
const result = runCli(['remember', 'test'], { ASSISTANT_DATA_DIR: '/tmp' });
assertSuccess(result.json);

// Assert errors
assertError(result.json, 'VALIDATION_ERROR');
```

## Testing 100x Features

### Testing Code Generation

```typescript
// Test generate tool script
import { spawnSync } from 'node:child_process';

const result = spawnSync(process.execPath, [
    'dist/scripts/generate_tool.js',
    'test_tool',
    '--args', 'text:string'
]);

assert.equal(result.status, 0);
assert.ok(fs.existsSync('src/tools/test_tool_tools.ts'));
```

### Testing Performance Profiling

```typescript
// Test profile command
const result = runCli(['profile', 'remember: test']);
const json = result.json;

assert.ok(json.ok);
assert.ok(typeof json.result.total_time_ms === 'number');
assert.ok(json.result.tool_name === 'remember');
```

### Testing Refactoring Tools

```typescript
// Test refactor script
const result = spawnSync(process.execPath, [
    'dist/scripts/refactor.js',
    'src/tools/my_tools.ts'
]);

assert.ok(result.stdout.includes('Found') || result.stdout.includes('No issues'));
```

## E2E Testing Patterns

### CLI Command Testing

```typescript
// Test full CLI workflow
const remember = runCli(['remember', 'test data']);
assertSuccess(remember.json);

const recall = runCli(['recall', 'test']);
assertSuccess(recall.json);
assert.ok(recall.json.result.entries.length > 0);
```

### Integration Testing

```typescript
// Test multiple components together
const context = createMockContext();
const executor = new Executor(/* ... */);

// Test full flow
const remember = await executor.execute('remember', { text: 'test' });
assertSuccess(remember);

const recall = await executor.execute('recall', { query: 'test' });
assertSuccess(recall);
assert.ok(recall.result.entries.length > 0);
```

## Coverage Analysis

Use coverage report generator:

```bash
# Generate coverage report
npm run test:coverage

# Analyze coverage gaps
node dist/scripts/test_coverage_report.js

# View HTML report
npm run test:coverage:open
```

## Cursor-Specific Testing Features

### Test Generation from Code

Cursor can help generate tests:

1. **Select code** → Ask Cursor: "Generate tests for this function"
2. **Right-click** → "Generate tests" (if extension available)
3. **Use test utilities** → Cursor suggests test patterns

### Test Suggestions

Cursor can suggest:
- Missing test cases
- Edge cases to test
- Error scenarios
- Integration test opportunities

### Test-Driven Development with Cursor

1. Write test first (Cursor helps with structure)
2. Implement feature (Cursor suggests implementation)
3. Run tests (Cursor shows results)
4. Refactor (Cursor suggests improvements)

## Test Organization

### Test Categories

```
src/
├── unit/              # Unit tests (if separated)
│   └── parsers/
├── integration/      # Integration tests (if separated)
│   └── executor.test.ts
├── e2e/              # E2E tests
│   └── cli_e2e.test.ts
└── scripts/          # Script tests
    └── generate_tool.test.ts
```

### Test Naming

- `*.test.ts` - Colocated with source (current pattern)
- `*_test.ts` - Alternative naming
- `*.spec.ts` - Spec-style naming

## Coverage Goals

### Minimum Coverage

- **Lines**: 80%
- **Functions**: 80%
- **Branches**: 80%
- **Statements**: 80%

### Priority Files

Must have high coverage:
- `src/core/executor.ts` - Core execution logic
- `src/core/validation.ts` - Validation logic
- `src/app/router.ts` - Routing logic
- `src/tools/*.ts` - All tool handlers

### Lower Priority

Can have lower coverage:
- `src/app/web/` - Web UI (if separate)
- `src/scripts/` - Utility scripts
- `src/benchmarks/` - Benchmark code

## Test Performance

### Parallel Execution

Tests run in parallel by default (4 workers):
```bash
npm test  # Parallel (default)
npm run test:parallel  # Explicit
npm run test:sequential  # Disable parallel
```

### Test Caching

Tests skip if unchanged:
```bash
npm test  # Skips cached tests
TEST_SKIP_CACHE=1 npm test  # Force run all
```

### Watch Mode

Auto-rerun on changes:
```bash
npm run test:watch
```

## Debugging Tests

### VS Code Debugger

1. Set breakpoint in test
2. Press F5 → "Debug Current Test"
3. Step through code

### Verbose Output

```bash
# Run with verbose output
TEST_DIST=1 node dist/run_tests.js executor 2>&1 | tee test.log

# Check test output file
cat src/executor.test.output.txt
```

## Test Best Practices

### ✅ Do This

- Use test utilities (`createMockContext`, `assertSuccess`)
- Test success and error cases
- Test edge cases (empty input, max size)
- Clean up test directories
- Use descriptive test names

### ❌ Don't Do This

- Don't rely on repo files for test data
- Don't skip cleanup (memory leaks)
- Don't use real API keys in tests
- Don't test implementation details
- Don't write flaky tests

## Integration with Other Rules

- **Tools Rule**: See `.cursor/rules/tools.mdc` for tool testing patterns
- **Security Rule**: See `.cursor/rules/security.mdc` for security test patterns
- **Errors Rule**: See `.cursor/rules/errors.mdc` for error testing patterns
