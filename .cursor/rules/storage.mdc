---
description: Data persistence and JSONL storage patterns
globs: ["src/storage/**/*.ts"]
alwaysApply: false
---

# Storage Patterns

## JSONL Format

Use JSONL (newline-delimited JSON) for append-friendly storage:

```typescript
// Each line is a valid JSON object
{"id":1,"text":"Buy milk","done":false,"created_at":"2024-01-01T00:00:00Z"}
{"id":2,"text":"Call mom","done":true,"created_at":"2024-01-02T00:00:00Z"}
```

## Reading JSONL Safely

Handle corrupt lines gracefully with quarantine:

```typescript
export function readJsonlSafely<T>(opts: {
    filePath: string;
    isValid: (entry: any) => boolean;
}): T[] {
    const { filePath, isValid } = opts;
    
    if (!fs.existsSync(filePath)) return [];
    
    const content = fs.readFileSync(filePath, 'utf8');
    const lines = content.split('\n').filter(line => line.trim());
    
    const valid: T[] = [];
    const corrupt: string[] = [];
    
    for (const line of lines) {
        try {
            const parsed = JSON.parse(line);
            if (isValid(parsed)) {
                valid.push(parsed);
            } else {
                corrupt.push(line);
            }
        } catch {
            corrupt.push(line);
        }
    }
    
    // Quarantine corrupt lines
    if (corrupt.length > 0) {
        const quarantinePath = filePath + '.corrupt';
        fs.appendFileSync(quarantinePath, corrupt.join('\n') + '\n');
        // Rewrite clean file
        writeJsonlAtomic(filePath, valid);
    }
    
    return valid;
}
```

## Atomic Writes

Prevent corruption with atomic write operations:

```typescript
export function writeJsonlAtomic<T>(filePath: string, entries: T[]): void {
    const tmpPath = filePath + '.tmp';
    const content = entries.map(e => JSON.stringify(e)).join('\n') + '\n';
    
    fs.writeFileSync(tmpPath, content, 'utf8');
    fs.renameSync(tmpPath, filePath);  // Atomic on POSIX
}
```

## Append Operations

For append-only logs, use simple append:

```typescript
export function appendJsonl<T>(filePath: string, entry: T): void {
    const line = JSON.stringify(entry) + '\n';
    fs.appendFileSync(filePath, line, 'utf8');
}
```

## Memory Store (JSON)

For small datasets, use simple JSON with full rewrite:

```typescript
interface MemoryStore {
    entries: MemoryEntry[];
}

export function readMemory(filePath: string): MemoryStore {
    if (!fs.existsSync(filePath)) {
        return { entries: [] };
    }
    
    try {
        const content = fs.readFileSync(filePath, 'utf8');
        const data = JSON.parse(content);
        return { entries: data.entries || [] };
    } catch {
        return { entries: [] };
    }
}

export function writeMemory(filePath: string, data: MemoryStore): void {
    const dir = path.dirname(filePath);
    if (!fs.existsSync(dir)) {
        fs.mkdirSync(dir, { recursive: true });
    }
    fs.writeFileSync(filePath, JSON.stringify(data, null, 2), 'utf8');
}
```

## Data Validation

Always validate entries when reading:

```typescript
// Type guard for validation
function isValidTask(entry: any): boolean {
    return (
        typeof entry === 'object' &&
        typeof entry.id === 'number' &&
        typeof entry.text === 'string' &&
        typeof entry.done === 'boolean'
    );
}

// Usage
const tasks = context.readJsonl<Task>(tasksPath, isValidTask);
```

## Data Directory Policy

Data files go in `~/.assistant-data/` by default:

```typescript
// Config resolution order:
// 1. ASSISTANT_DATA_DIR env var
// 2. ASSISTANT_BASE_DIR + '/.assistant-data/'
// 3. ~/.assistant-data/ (fallback)

const dataDir = process.env.ASSISTANT_DATA_DIR 
    || path.join(process.env.ASSISTANT_BASE_DIR || os.homedir(), '.assistant-data');
```

## File Paths in Context

Storage paths are provided via ExecutorContext:

```typescript
interface ExecutorContext {
    memoryPath: string;      // memory.json
    tasksPath: string;       // tasks.jsonl
    memoryLogPath: string;   // memory.jsonl (append-only)
    remindersPath: string;   // reminders.jsonl
    emailsPath: string;      // emails.jsonl
    messagesPath: string;    // messages.jsonl
    contactsPath: string;    // contacts.jsonl
    calendarPath: string;    // calendar.jsonl
    permissionsPath: string; // permissions.json
    auditPath: string;       // audit.jsonl
}
```

## Schema Migration

When adding fields to stored data:

### 1. Make New Fields Optional

```typescript
// Old schema
const TaskSchemaV1 = z.object({
    id: z.number(),
    text: z.string(),
    done: z.boolean(),
});

// New schema - priority is optional for backward compat
const TaskSchemaV2 = z.object({
    id: z.number(),
    text: z.string(),
    done: z.boolean(),
    priority: z.enum(['low', 'medium', 'high']).optional(),  // NEW
    created_at: z.string().optional(),  // NEW
});
```

### 2. Handle Missing Fields on Read

```typescript
function normalizeTask(raw: any): Task {
    return {
        id: raw.id,
        text: raw.text,
        done: raw.done,
        priority: raw.priority || null,           // Default for old data
        created_at: raw.created_at || new Date().toISOString(),
    };
}
```

### 3. Write Migration (if needed)

```typescript
function migrateTasksV1toV2(filePath: string): void {
    const tasks = readJsonlSafely<any>(filePath, isTaskV1);
    
    const migrated = tasks.map(task => ({
        ...task,
        priority: null,
        created_at: new Date().toISOString(),
    }));
    
    writeJsonlAtomic(filePath, migrated);
}
```

## Backup Before Destructive Operations

```typescript
function backupFile(filePath: string): string {
    const backupPath = `${filePath}.backup.${Date.now()}`;
    if (fs.existsSync(filePath)) {
        fs.copyFileSync(filePath, backupPath);
    }
    return backupPath;
}

// Usage before migration
const backup = backupFile(tasksPath);
try {
    migrateTasksV1toV2(tasksPath);
} catch (err) {
    // Restore from backup
    fs.copyFileSync(backup, tasksPath);
    throw err;
}
```

## Data Integrity Checks

Periodically verify data integrity:

```typescript
function checkDataIntegrity(filePath: string): {
    valid: number;
    corrupt: number;
    errors: string[];
} {
    const errors: string[] = [];
    let valid = 0;
    let corrupt = 0;
    
    const content = fs.readFileSync(filePath, 'utf8');
    const lines = content.split('\n').filter(l => l.trim());
    
    for (let i = 0; i < lines.length; i++) {
        try {
            const parsed = JSON.parse(lines[i]);
            if (isValidEntry(parsed)) {
                valid++;
            } else {
                corrupt++;
                errors.push(`Line ${i + 1}: Invalid schema`);
            }
        } catch {
            corrupt++;
            errors.push(`Line ${i + 1}: Invalid JSON`);
        }
    }
    
    return { valid, corrupt, errors };
}
```
